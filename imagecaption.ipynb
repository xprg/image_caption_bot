{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"imagecaption.ipynb","private_outputs":true,"provenance":[],"mount_file_id":"1pfrax7_iuSXnDq48lsZCWQCYCxHAsvOe","authorship_tag":"ABX9TyP2kU/jBAGCw3hTpX9yAy1E"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"TPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"5cAjYMNjxhQf"},"source":["intial caption\n"]},{"cell_type":"code","metadata":{"id":"6yebf4z9nsal"},"source":["!unzip 'drive/MyDrive/flickr.zip'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"rnK8u8r7m6Eq"},"source":["def readTextfile(path):\n","  with open(path) as file:\n","    captions=file.read()\n","  return captions"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"PjQzC1t7oohu"},"source":["captions=readTextfile('captions.txt')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Uj9TpMIqpFy5"},"source":["caption_list=captions.split('\\n')\n","caption_list=caption_list[:-1]\n","caption_list=caption_list[1:]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"EPoHBr6gptm7"},"source":["descriptions={}\n","\n","for x in caption_list:\n","  first,second= x.split('.jpg,')\n","  img_name=first\n","\n","  if descriptions.get(img_name) is None:\n","    descriptions[img_name]=[]\n","  \n","  descriptions[img_name].append(second)\n","      "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MGN745xruWiY"},"source":["import re\n","\n","def clean_text(sentence):                           #not doing stemming lemmanization and stopword removal for human like output...\n","  sentence=sentence.lower()\n","  sentence=re.sub(\"[^a-z]\",\" \",sentence)\n","  sentence=sentence.split()\n","\n","  sentence=\" \".join(sentence)\n","\n","  return sentence\n","\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1WZrqDfa0QFz"},"source":["for key,cap in descriptions.items():\n","  for i in range(len(cap)):\n","    cap[i]=clean_text(cap[i])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dxMz3JQy2A81"},"source":["with open(\"drive/MyDrive/descriptions.txt\",'w') as f:                         #saving in descriptions.txt\n","  f.write(str(descriptions))\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"H5GKrLJz3uKa"},"source":["**Vocab\n","**"]},{"cell_type":"code","metadata":{"id":"wwqTzHA930wh"},"source":["import json\n","\n","descriptions=None\n","\n","with open('/content/drive/MyDrive/descriptions.txt','r') as f:\n","  descriptions=f.read()\n","\n","json_acceptable_string=descriptions.replace(\"'\",\"\\\"\")\n","descriptions=json.loads(json_acceptable_string)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"b2y5E_Dh6cBF"},"source":["vocab=set()                                                      #vocab created\n","\n","for cap in descriptions.values():\n","  for sentence in cap:\n","    vocab.update(sentence.split())\n","\n","\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"OVbOJtBD9qGc"},"source":["import collections\n","\n","total_words=[]\n","for key in descriptions.keys():\n","  for s in descriptions[key]:\n","    for word in s.split():\n","      total_words.append(word)\n","\n","\n","counter=collections.Counter(total_words)\n","freq_count=dict(counter)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"IXZbNbECCP33"},"source":["sorted_freq=sorted(freq_count.items(),reverse=True,key=lambda x:x[1]) "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"rSlqiProGPjb"},"source":["threshold=10                # min frequency for word's consideration\n","\n","freq=[x for x in sorted_freq if x[1]>threshold ]\n","\n","freq_vocab=[x[0] for x in freq]\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1ecwD3YQ6Evj"},"source":["import pickle\n","\n","f=open('/content/drive/MyDrive/encoded_train.pkl','rb')\n","train=pickle.load(f)\n","f.close()\n","\n","train_descriptions={}\n","test=[]\n","                                             #for reloading the train/test set....not to be done multiple times\n","\n","for key in descriptions.keys():\n","\n","  if train.get(key) is not None:\n","    train_descriptions[key]=[]\n","    for sentence in descriptions[key]:\n","       train_descriptions[key].append(\"<s> \"+sentence+\" <e>\")\n","  \n","  else:\n","    test.append(key)\n","  \n","\n","\n","\n","\n","\n","\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"W2olzD4wJffo"},"source":["###  Train/test\n","  \n","\n","\n"]},{"cell_type":"code","metadata":{"id":"eeM4bZNKJx5O"},"source":["\n","                 #run ONLY ONCE\n","\n","train_descriptions={}\n","\n","test=[]\n","                                                                  # random train/test split (85/15)\n","import random\n","\n","for key in descriptions.keys():\n","  choice=random.random()\n","  if choice <=0.80:\n","    train_descriptions[key]=[]\n","\n","    for sentence in descriptions[key]:\n","      train_descriptions[key].append(\"<s> \"+sentence+\" <e>\")\n","  \n","  else:\n","    test.append(key)\n","\n","\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bpHawiRmprWH"},"source":["print(len(train_descriptions))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"JxTa5nPkw9-3"},"source":["test=test[:1000] \n","                                  # 1000 testing images"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Gakt237_XNC0"},"source":["*image preprocessing *\n","\n","\n","\n"]},{"cell_type":"code","metadata":{"id":"yPjtJkWqXghT"},"source":["from keras.applications.resnet50 import ResNet50\n","from keras.layers import *\n","from keras.models import Model\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Vwk6vZ4FXac0"},"source":["model=ResNet50(weights='imagenet',input_shape=(224,224,3))\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"V2CvC_DMeKhW"},"source":["model.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QkfOzb0mZVDy"},"source":["model_new=Model(model.input,model.layers[-2].output)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9BiaY165auvS"},"source":["from keras.preprocessing import image\n","from tensorflow.keras.applications.resnet50 import preprocess_input, decode_predictions\n","                                                                                     \n","def img_preprocess(img_path):\n","  img=image.load_img(img_path,target_size=(224,224,3))\n","  img=image.img_to_array(img)                                 \n","  img=img.reshape(-1,224,224,3)\n","# resnet 50 preprocessing function\n","  img=preprocess_input(img)\n","  return img\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"uCk3EOdhgLPR"},"source":["def encode_img(img):\n","  img=img_preprocess(img)\n","  features=model_new.predict(img)\n","\n","  feature_vec=features.reshape((-1,))\n","  return feature_vec\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ri6-O6SKj1Iz"},"source":["train_encoded={}\n","IMG_PATH=\"Images\"\n","c=0\n","for key in train_descriptions.keys():\n","  img_data=encode_img(IMG_PATH+\"/\"+key+\".jpg\")\n","\n","  train_encoded[key]=img_data\n","  if c<100:\n","    c+=1\n","  else:\n","    print(\"one batch done\")\n","    c=0\n","\n","import pickle\n","\n","with open(\"drive/MyDrive/encoded_train.pkl\",'wb') as f:\n","  pickle.dump(train_encoded,f)  \n","  "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZNDymWjjpQI5"},"source":["print(len(train_encoded))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"N-Bv8khltb7P"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"oiLKMqtWvDgS"},"source":["test_encoded={}\n","IMG_PATH=\"Images\"\n","c=0\n","for t in test:\n","  img_data=encode_img(IMG_PATH+\"/\"+t+\".jpg\")\n","  test_encoded[t]=img_data\n","\n","  if c%100==0:\n","    print(c/100)\n","  c+=1\n","\n","with open(\"drive/MyDrive/encoded_test.pkl\",'wb') as f:\n","  pickle.dump(test_encoded,f)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"U_9eA330wX6n"},"source":["import pickle\n","with open('/content/drive/MyDrive/encoded_train.pkl','rb') as f:\n","  encoded_train=pickle.load(f)\n","\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xmdJPACu0w6w"},"source":["train_descriptions={}\n","for t in encoded_train.keys():\n","  train_descriptions[t]=[]\n","  for s in descriptions[t]:\n","    train_descriptions[t].append(\"<s> \"+s+\" <e>\")\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_T9zbvOj1j8z"},"source":["# text preprocessing\n"]},{"cell_type":"code","metadata":{"id":"Dg4Z0vmCgDCi"},"source":["print(len(freq_vocab))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"loL8xwCR1ffp"},"source":["vocab=[]\n","vocab=freq_vocab\n","\n","word_idx={}\n","idx_word={}\n","\n","for ix,word in enumerate(vocab):\n","  word_idx[vocab[ix]]=ix+1\n","  idx_word[ix+1]=vocab[ix]\n","  \n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"BC2A6slTh8z-"},"source":["print(word_idx['cannon'])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"C8c2KWT32wGb"},"source":["idx_word[1851]=\"<s>\"\n","word_idx[\"<s>\"]=1851\n","                                   #adding start seq and end seq to vocabulary\n","idx_word[1852]=\"<e>\"\n","word_idx[\"<e>\"]=1852\n","\n","vocab_size=len(word_idx)+1"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Mw2g-VkwRGru"},"source":["import pickle\n","\n","f=open('drive/MyDrive/word_idx.pkl','wb')\n","pickle.dump(word_idx,f)\n","f.close()\n","\n","f=open('drive/MyDrive/idx_word.pkl','wb')\n","pickle.dump(idx_word,f)\n","f.close()\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5MERccoCL2lZ"},"source":["# data generator\n"]},{"cell_type":"code","metadata":{"id":"dKvbucNdBqjf"},"source":["from keras.preprocessing.sequence import pad_sequences\n","from tensorflow.keras.utils import to_categorical\n","import numpy as np\n","\n","\n","def data_generator(train_descriptions,encoded_train,word_idx,maxlen,batch_size):\n","  x1,x2,y= [],[],[]\n","\n","  n=0\n","  while True:\n","    \n","    for key,data in train_descriptions.items():\n","      n+=1\n","\n","      photo=encoded_train[key]\n","      for desc in data:\n","        seq=[word_idx[x] for x in desc.split() if x in word_idx]\n","        for i in range(1,len(seq)):\n","          xi=seq[0:i]                   #generating and padding\n","          yi=seq[i]\n","          \n","          xi=pad_sequences([xi],maxlen=maxlen,value=0,padding=\"post\",truncating='post')[0]\n","\n","          yi=to_categorical([yi],num_classes=len(word_idx)+1)[0]\n","      \n","          x1.append(photo)\n","          x2.append(xi)\n","          y.append(yi)\n","          \n","\n","        if n==batch_size:\n","        \n","          yield([np.array(x1),np.array(x2)],np.array(y))\n","\n","          n=0\n","          x1,x2,y= [],[],[]\n","\n","        \n","\n","          \n","      "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"AxTQshSsW0J5"},"source":["# Glove embedding\n"]},{"cell_type":"code","metadata":{"id":"Fd0xlIreW71W"},"source":["  import numpy as np\n","\n","\n","  f=open('/content/drive/MyDrive/glove.6B.50d.txt','r',encoding='utf-8')\n","\n","  word_embedding={}\n","\n","  lines=f.readlines()\n","  f.close()\n","\n","  for line in lines:\n","    line=line.split()\n","    word=line[0]\n","    word_embedding[word]=np.array(line[1:],dtype='float')\n","  \n","  \n","    \n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xFb21JC1ceHY"},"source":["def form_embeddding_matrix(word_idx):\n","  embedd_dim=50\n","  vocab_size=len(word_idx)+1                         # 0 index refers to padding\n","  matrix=np.zeros((vocab_size,embedd_dim))\n","\n","  for w,i in word_idx.items():\n","    embedding_values=word_embedding.get(w)\n","    if embedding_values is not None:\n","      matrix[i]=embedding_values\n","\n","  return matrix\n","\n","embedding_matrix=form_embeddding_matrix(word_idx)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vq34RHVsLen-"},"source":["Image caption model"]},{"cell_type":"code","metadata":{"id":"uB1AhuGDe-2-"},"source":["import tensorflow.keras\n","\n","max_len=16\n","\n","from tensorflow.keras.layers import *\n","from tensorflow.keras import Input\n","\n","# img features input\n","input_img_features=Input(shape=(2048,))\n","inp_img1=Dropout(0.3)(input_img_features)\n","inp_img2=Dense(256,activation='relu')(inp_img1)\n","\n","vocab_size=len(word_idx)+1\n","# caption input\n","input_captions=Input(shape=(max_len,))\n","inp_cap1=Embedding(input_dim=vocab_size,output_dim=50,mask_zero=True)(input_captions)\n","inp_cap2=Dropout(0.3)(inp_cap1)\n","inp_cap3=LSTM(256)(inp_cap2)\n","\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"27mL4iFKu72r"},"source":["print(inp_img1.shape)\n","print(input_img_features.shape)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tif9bDRdQayc"},"source":["#decoder\n","\n","decoder1=add([inp_img2,inp_cap3])\n","decoder2=Dense(256,activation='relu')(decoder1)\n","outputs=Dense(vocab_size,activation='softmax')(decoder2)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tWYJZl1SSRBD"},"source":["from tensorflow.keras.models import Model\n","\n","model_x=Model(inputs=[input_img_features,input_captions],outputs=outputs)\n","model_x.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zDHVZV3Zat6z"},"source":["#setting embedding weights\n","\n","model_x.layers[2].set_weights([embedding_matrix])\n","model_x.layers[2].trainable=False"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4EROE8xNcW7x"},"source":["model_x.compile(optimizer='adam',loss='categorical_crossentropy')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"IUePOAJFeCQT"},"source":["Train>>>...\n"]},{"cell_type":"code","metadata":{"id":"5uj_AmCk2FwO"},"source":["model_x.load_weights('/content/drive/MyDrive/latest.h5')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8SEjM_36c4JM"},"source":["\n","\n","def train_model(epochs,batch_size):\n","  \n","  steps=len(encoded_train)//batch_size\n","  for i in range(epochs):\n","    generator=data_generator(train_descriptions,encoded_train,word_idx,16,3)\n","    model_x.fit_generator(generator,epochs=1,verbose=1,steps_per_epoch=steps)\n","    print('epoch complete')\n","    if i==(epochs-1):\n","      model_x.save(\"drive/MyDrive/latest\"+\".h5\")\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1Cj1ZV1Khhse"},"source":["train_model(8,3)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LFJVPno1je7P"},"source":["from keras.models import load_model\n","model_x=load_model('/content/drive/MyDrive/imgcap_5.h5')\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hR1LoB01kHyi"},"source":["def predict_caption(photo):\n","  ans=\"<s>\"\n","\n","  for i in range(max_len):\n","    seq=[word_idx[x] for x in ans.split() if x in word_idx]\n","    seq=pad_sequences([seq],maxlen=max_len,padding='post')\n","\n","    y=model_x.predict([photo,seq])\n","    y_final=y.argmax()\n","    word=idx_word[y_final]\n","\n","    ans+=(\" \"+word)\n","    if(word==\"<e>\"):\n","      break\n","  \n","  ans=ans.split()\n","  caption=ans[1:-1]\n","  caption=\" \".join(caption)\n","  \n","  return caption"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"baHqfwB3m-l_"},"source":["                                                         # some manual testing\n","photo_list=list(train_encoded.keys())\n","import matplotlib.pyplot as plt\n","\n","\n","for i in range(6):\n","  num=np.random.randint(0,1000)\n","  img_num=photo_list[num]\n","\n","  img_encoding=train_encoded[img_num].reshape(1,2048)\n","  cap=predict_caption(img_encoding)\n","\n","  image=plt.imread(\"/content/Images/\"+img_num+\".jpg\")\n","  plt.imshow(image)\n","  plt.axis(\"off\")\n","  plt.show()\n","  print(cap)\n","\n","\n","\n","\n","\n","  \n","\n"],"execution_count":null,"outputs":[]}]}